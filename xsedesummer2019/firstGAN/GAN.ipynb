{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used dcgan-oreilly/DCGANs with TensorFlow tutorial\n",
    "\n",
    "# import helper\n",
    "\n",
    "data_dir = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from glob import glob\n",
    "from matplotlib import pyplot\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Image configuration\n",
    "IMAGE_HEIGHT = 28\n",
    "IMAGE_WIDTH = 28\n",
    "data_files = glob(os.path.join(data_dir, 'imgs/*.jpg'))\n",
    "shape = len(data_files), IMAGE_WIDTH, IMAGE_HEIGHT, 3\n",
    "\n",
    "def get_image(image_path, width, height, mode):\n",
    "    \"\"\"\n",
    "    Read image from image_path\n",
    "    \"\"\"\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    if image.size != (width, height):\n",
    "        # Remove most pixels that aren't part of a face\n",
    "        face_width = face_height = 108\n",
    "        j = (image.size[0] - face_width) // 2\n",
    "        i = (image.size[1] - face_height) // 2\n",
    "        image = image.crop([j, i, j + face_width, i + face_height])\n",
    "        image = image.resize([width, height], Image.BILINEAR)\n",
    "\n",
    "    return np.array(image.convert(mode))\n",
    "\n",
    "def get_batch(image_files, width, height, mode='RGB'):\n",
    "    \"\"\"\n",
    "    Get a single image\n",
    "    \"\"\"\n",
    "    data_batch = np.array(\n",
    "        [get_image(sample_file, width, height, mode) for sample_file in image_files]).astype(np.float32)\n",
    "\n",
    "    # Make sure the images are in 4 dimensions\n",
    "    if len(data_batch.shape) < 4:\n",
    "        data_batch = data_batch.reshape(data_batch.shape + (1,))\n",
    "\n",
    "    return data_batch\n",
    "\n",
    "def get_batches(batch_size):\n",
    "    \"\"\"\n",
    "    Generate batches\n",
    "    \"\"\"\n",
    "    IMAGE_MAX_VALUE = 255\n",
    "\n",
    "\n",
    "    current_index = 0\n",
    "    while current_index + batch_size <= shape[0]:\n",
    "        data_batch = get_batch(\n",
    "            data_files[current_index:current_index + batch_size],\n",
    "            *shape[1:3])\n",
    "\n",
    "        current_index += batch_size\n",
    "\n",
    "        yield data_batch / IMAGE_MAX_VALUE - 0.5\n",
    "        \n",
    "\n",
    "test_images = get_batch(glob(os.path.join(data_dir, 'imgs/*.jpg'))[:10], 56, 56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[  8.  14.   1.]\n",
      "   [  8.  14.   3.]\n",
      "   [  8.  14.   3.]\n",
      "   ...\n",
      "   [  8.  14.   0.]\n",
      "   [  8.  14.   0.]\n",
      "   [  8.  14.   0.]]\n",
      "\n",
      "  [[  8.  14.   1.]\n",
      "   [  8.  14.   4.]\n",
      "   [  7.  13.   3.]\n",
      "   ...\n",
      "   [  8.  14.   0.]\n",
      "   [  8.  14.   0.]\n",
      "   [  8.  14.   0.]]\n",
      "\n",
      "  [[  8.  14.   1.]\n",
      "   [  8.  14.   5.]\n",
      "   [  7.  13.   4.]\n",
      "   ...\n",
      "   [  8.  14.   0.]\n",
      "   [  8.  14.   0.]\n",
      "   [  8.  14.   0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[105. 122.  76.]\n",
      "   [109. 122.  75.]\n",
      "   [126. 133.  86.]\n",
      "   ...\n",
      "   [106.  82.  63.]\n",
      "   [187. 178. 135.]\n",
      "   [196. 190. 126.]]\n",
      "\n",
      "  [[115. 128.  77.]\n",
      "   [115. 123.  75.]\n",
      "   [134. 136.  92.]\n",
      "   ...\n",
      "   [ 35.  29.  17.]\n",
      "   [ 88.  90.  60.]\n",
      "   [159. 157. 107.]]\n",
      "\n",
      "  [[134. 141.  86.]\n",
      "   [131. 134.  85.]\n",
      "   [148. 143. 103.]\n",
      "   ...\n",
      "   [  7.  12.   5.]\n",
      "   [ 22.  31.  14.]\n",
      "   [ 87.  89.  57.]]]\n",
      "\n",
      "\n",
      " [[[ 63.  81. 126.]\n",
      "   [ 67.  84. 124.]\n",
      "   [ 72.  86. 119.]\n",
      "   ...\n",
      "   [ 55.  68. 103.]\n",
      "   [ 54.  67. 102.]\n",
      "   [ 53.  66. 101.]]\n",
      "\n",
      "  [[ 68.  84. 126.]\n",
      "   [ 73.  87. 122.]\n",
      "   [ 82.  91. 118.]\n",
      "   ...\n",
      "   [ 55.  68. 103.]\n",
      "   [ 54.  67. 102.]\n",
      "   [ 53.  66. 101.]]\n",
      "\n",
      "  [[ 70.  84. 121.]\n",
      "   [ 75.  84. 114.]\n",
      "   [ 79.  82. 101.]\n",
      "   ...\n",
      "   [ 55.  68. 103.]\n",
      "   [ 54.  67. 102.]\n",
      "   [ 53.  66. 101.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[138. 105.  93.]\n",
      "   [184. 140. 126.]\n",
      "   [188. 143. 124.]\n",
      "   ...\n",
      "   [166. 130. 101.]\n",
      "   [128. 109. 103.]\n",
      "   [ 63.  70.  88.]]\n",
      "\n",
      "  [[151. 119. 104.]\n",
      "   [190. 148. 133.]\n",
      "   [197. 150. 134.]\n",
      "   ...\n",
      "   [159. 122.  84.]\n",
      "   [106.  90.  84.]\n",
      "   [ 60.  67.  90.]]\n",
      "\n",
      "  [[167. 134. 117.]\n",
      "   [194. 153. 137.]\n",
      "   [201. 154. 139.]\n",
      "   ...\n",
      "   [136. 109.  78.]\n",
      "   [ 82.  75.  79.]\n",
      "   [ 59.  68. 102.]]]\n",
      "\n",
      "\n",
      " [[[ 20.  16.   8.]\n",
      "   [ 11.   6.   2.]\n",
      "   [  6.   2.   1.]\n",
      "   ...\n",
      "   [208. 200. 196.]\n",
      "   [209. 206. 200.]\n",
      "   [208. 207. 201.]]\n",
      "\n",
      "  [[ 12.   7.   2.]\n",
      "   [  7.   2.   0.]\n",
      "   [  8.   4.   3.]\n",
      "   ...\n",
      "   [211. 205. 201.]\n",
      "   [210. 208. 203.]\n",
      "   [211. 212. 206.]]\n",
      "\n",
      "  [[ 11.   6.   2.]\n",
      "   [ 10.   5.   2.]\n",
      "   [ 14.   9.   8.]\n",
      "   ...\n",
      "   [205. 200. 197.]\n",
      "   [210. 208. 204.]\n",
      "   [213. 214. 209.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[125.  90.  67.]\n",
      "   [145. 103.  76.]\n",
      "   [160. 115.  82.]\n",
      "   ...\n",
      "   [198. 187. 168.]\n",
      "   [213. 209. 193.]\n",
      "   [213. 216. 202.]]\n",
      "\n",
      "  [[120.  86.  63.]\n",
      "   [139. 101.  71.]\n",
      "   [157. 114.  79.]\n",
      "   ...\n",
      "   [199. 191. 171.]\n",
      "   [215. 212. 197.]\n",
      "   [208. 210. 197.]]\n",
      "\n",
      "  [[115.  83.  59.]\n",
      "   [135. 100.  68.]\n",
      "   [154. 115.  77.]\n",
      "   ...\n",
      "   [202. 197. 175.]\n",
      "   [218. 216. 201.]\n",
      "   [204. 205. 193.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[186. 150. 109.]\n",
      "   [181. 146. 106.]\n",
      "   [175. 141. 100.]\n",
      "   ...\n",
      "   [ 68.  99. 124.]\n",
      "   [ 71. 101. 125.]\n",
      "   [ 73. 102. 126.]]\n",
      "\n",
      "  [[184. 149. 109.]\n",
      "   [181. 148. 107.]\n",
      "   [177. 144. 104.]\n",
      "   ...\n",
      "   [ 68. 100. 125.]\n",
      "   [ 71. 102. 126.]\n",
      "   [ 73. 103. 128.]]\n",
      "\n",
      "  [[188. 155. 114.]\n",
      "   [187. 153. 114.]\n",
      "   [183. 151. 112.]\n",
      "   ...\n",
      "   [ 68. 101. 127.]\n",
      "   [ 71. 103. 128.]\n",
      "   [ 73. 104. 129.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[222. 183. 154.]\n",
      "   [185. 135. 104.]\n",
      "   [166. 106.  74.]\n",
      "   ...\n",
      "   [ 89.  91.  89.]\n",
      "   [ 84.  90.  95.]\n",
      "   [ 38.  47.  55.]]\n",
      "\n",
      "  [[224. 192. 163.]\n",
      "   [200. 162. 133.]\n",
      "   [148. 102.  73.]\n",
      "   ...\n",
      "   [ 98.  95.  90.]\n",
      "   [ 77.  80.  81.]\n",
      "   [ 36.  46.  52.]]\n",
      "\n",
      "  [[226. 198. 169.]\n",
      "   [216. 187. 160.]\n",
      "   [171. 138. 112.]\n",
      "   ...\n",
      "   [103.  96.  88.]\n",
      "   [ 79.  79.  77.]\n",
      "   [ 33.  44.  48.]]]\n",
      "\n",
      "\n",
      " [[[ 14.  13.  11.]\n",
      "   [ 20.  17.  15.]\n",
      "   [ 25.  21.  20.]\n",
      "   ...\n",
      "   [ 75.  69.  38.]\n",
      "   [ 99.  93.  64.]\n",
      "   [ 96.  89.  66.]]\n",
      "\n",
      "  [[ 13.  12.  10.]\n",
      "   [ 21.  18.  16.]\n",
      "   [ 29.  25.  22.]\n",
      "   ...\n",
      "   [ 78.  75.  49.]\n",
      "   [ 60.  56.  31.]\n",
      "   [ 60.  55.  40.]]\n",
      "\n",
      "  [[ 17.  16.  14.]\n",
      "   [ 26.  22.  21.]\n",
      "   [ 35.  29.  26.]\n",
      "   ...\n",
      "   [150. 150. 118.]\n",
      "   [ 76.  76.  43.]\n",
      "   [ 80.  78.  58.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[182. 177. 153.]\n",
      "   [171. 161. 139.]\n",
      "   [176. 163. 140.]\n",
      "   ...\n",
      "   [138. 130. 138.]\n",
      "   [146. 137. 142.]\n",
      "   [162. 150. 153.]]\n",
      "\n",
      "  [[173. 167. 146.]\n",
      "   [170. 161. 140.]\n",
      "   [170. 157. 136.]\n",
      "   ...\n",
      "   [196. 193. 195.]\n",
      "   [203. 199. 198.]\n",
      "   [210. 204. 202.]]\n",
      "\n",
      "  [[154. 146. 128.]\n",
      "   [163. 153. 135.]\n",
      "   [164. 151. 131.]\n",
      "   ...\n",
      "   [227. 226. 224.]\n",
      "   [229. 225. 224.]\n",
      "   [218. 213. 212.]]]\n",
      "\n",
      "\n",
      " [[[186. 158. 134.]\n",
      "   [186. 158. 134.]\n",
      "   [186. 158. 134.]\n",
      "   ...\n",
      "   [118. 120.  96.]\n",
      "   [117. 120.  95.]\n",
      "   [118. 121.  94.]]\n",
      "\n",
      "  [[186. 158. 134.]\n",
      "   [186. 158. 134.]\n",
      "   [186. 158. 134.]\n",
      "   ...\n",
      "   [114. 116.  93.]\n",
      "   [117. 120.  94.]\n",
      "   [120. 123.  96.]]\n",
      "\n",
      "  [[186. 158. 134.]\n",
      "   [186. 158. 134.]\n",
      "   [186. 158. 134.]\n",
      "   ...\n",
      "   [112. 114.  91.]\n",
      "   [117. 120.  94.]\n",
      "   [121. 124.  97.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[189. 161. 137.]\n",
      "   [189. 161. 137.]\n",
      "   [188. 160. 136.]\n",
      "   ...\n",
      "   [130. 132. 108.]\n",
      "   [129. 131. 107.]\n",
      "   [130. 132. 108.]]\n",
      "\n",
      "  [[188. 160. 136.]\n",
      "   [188. 160. 136.]\n",
      "   [188. 160. 136.]\n",
      "   ...\n",
      "   [127. 134. 104.]\n",
      "   [127. 133. 104.]\n",
      "   [129. 133. 105.]]\n",
      "\n",
      "  [[188. 160. 136.]\n",
      "   [188. 160. 136.]\n",
      "   [188. 160. 136.]\n",
      "   ...\n",
      "   [125. 135. 100.]\n",
      "   [127. 134. 101.]\n",
      "   [129. 134. 103.]]]]\n"
     ]
    }
   ],
   "source": [
    "print(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def model_inputs(image_width, image_height, image_channels, z_dim):\n",
    "    \"\"\"\n",
    "    Create the model inputs\n",
    "    \"\"\"\n",
    "    inputs_real = tf.placeholder(tf.float32, shape=(None, image_width, image_height, image_channels), name='input_real') \n",
    "    inputs_z = tf.placeholder(tf.float32, (None, z_dim), name='input_z')\n",
    "    learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "    \n",
    "    return inputs_real, inputs_z, learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(images, reuse=False):\n",
    "    \"\"\"\n",
    "    Create the discriminator network\n",
    "    \"\"\"\n",
    "    alpha = 0.2\n",
    "    \n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        # using 4 layer network as in DCGAN Paper\n",
    "        \n",
    "        # Conv 1\n",
    "        conv1 = tf.layers.conv2d(images, 64, 5, 2, 'SAME')\n",
    "        lrelu1 = tf.maximum(alpha * conv1, conv1)\n",
    "        \n",
    "        # Conv 2\n",
    "        conv2 = tf.layers.conv2d(lrelu1, 128, 5, 2, 'SAME')\n",
    "        batch_norm2 = tf.layers.batch_normalization(conv2, training=True)\n",
    "        lrelu2 = tf.maximum(alpha * batch_norm2, batch_norm2)\n",
    "        \n",
    "        # Conv 3\n",
    "        conv3 = tf.layers.conv2d(lrelu2, 256, 5, 1, 'SAME')\n",
    "        batch_norm3 = tf.layers.batch_normalization(conv3, training=True)\n",
    "        lrelu3 = tf.maximum(alpha * batch_norm3, batch_norm3)\n",
    "       \n",
    "        # Flatten\n",
    "        flat = tf.reshape(lrelu3, (-1, 4*4*256))\n",
    "        \n",
    "        # Logits\n",
    "        logits = tf.layers.dense(flat, 1)\n",
    "        \n",
    "        # Output\n",
    "        out = tf.sigmoid(logits)\n",
    "        \n",
    "        return out, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z, out_channel_dim, is_train=True):\n",
    "    \"\"\"\n",
    "    Create the generator network\n",
    "    \"\"\"\n",
    "    alpha = 0.2\n",
    "    \n",
    "    with tf.variable_scope('generator', reuse=False if is_train==True else True):\n",
    "        # First fully connected layer\n",
    "        x_1 = tf.layers.dense(z, 2*2*512)\n",
    "        \n",
    "        # Reshape it to start the convolutional stack\n",
    "        deconv_2 = tf.reshape(x_1, (-1, 2, 2, 512))\n",
    "        batch_norm2 = tf.layers.batch_normalization(deconv_2, training=is_train)\n",
    "        lrelu2 = tf.maximum(alpha * batch_norm2, batch_norm2)\n",
    "        \n",
    "        # Deconv 1\n",
    "        deconv3 = tf.layers.conv2d_transpose(lrelu2, 256, 5, 2, padding='VALID')\n",
    "        batch_norm3 = tf.layers.batch_normalization(deconv3, training=is_train)\n",
    "        lrelu3 = tf.maximum(alpha * batch_norm3, batch_norm3)\n",
    "        \n",
    "        \n",
    "        # Deconv 2\n",
    "        deconv4 = tf.layers.conv2d_transpose(lrelu3, 128, 5, 2, padding='SAME')\n",
    "        batch_norm4 = tf.layers.batch_normalization(deconv4, training=is_train)\n",
    "        lrelu4 = tf.maximum(alpha * batch_norm4, batch_norm4)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.conv2d_transpose(lrelu4, out_channel_dim, 5, 2, padding='SAME')\n",
    "        \n",
    "        out = tf.tanh(logits)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(input_real, input_z, out_channel_dim):\n",
    "    \"\"\"\n",
    "    Get the loss for the discriminator and generator\n",
    "    \"\"\"\n",
    "    \n",
    "    label_smoothing = 0.9\n",
    "    \n",
    "    g_model = generator(input_z, out_channel_dim)\n",
    "    d_model_real, d_logits_real = discriminator(input_real)\n",
    "    d_model_fake, d_logits_fake = discriminator(g_model, reuse=True)\n",
    "    \n",
    "    d_loss_real = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real,\n",
    "                                                labels=tf.ones_like(d_model_real) * label_smoothing))\n",
    "    d_loss_fake = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n",
    "                                                labels=tf.zeros_like(d_model_fake)))\n",
    "    \n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "                                                  \n",
    "    g_loss = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n",
    "                                                labels=tf.ones_like(d_model_fake) * label_smoothing))\n",
    "    \n",
    "    \n",
    "    return d_loss, g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(d_loss, g_loss, learning_rate, beta1):\n",
    "    \"\"\"\n",
    "    Get optimization operations\n",
    "    \"\"\"\n",
    "    t_vars = tf.trainable_variables()\n",
    "    d_vars = [var for var in t_vars if var.name.startswith('discriminator')]\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "\n",
    "    # Optimize\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): \n",
    "        d_train_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(d_loss, var_list=d_vars)\n",
    "        g_train_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(g_loss, var_list=g_vars)\n",
    "\n",
    "    return d_train_opt, g_train_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_generator_output(sess, n_images, input_z, out_channel_dim):\n",
    "    \"\"\"\n",
    "    Show example output for the generator\n",
    "    \"\"\"\n",
    "    z_dim = input_z.get_shape().as_list()[-1]\n",
    "    example_z = np.random.uniform(-1, 1, size=[n_images, z_dim])\n",
    "\n",
    "    samples = sess.run(\n",
    "        generator(input_z, out_channel_dim, False),\n",
    "        feed_dict={input_z: example_z})\n",
    "\n",
    "    #pyplot.imshow(helper.images_square_grid(samples))\n",
    "    #pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch_count, batch_size, z_dim, learning_rate, beta1, get_batches, data_shape):\n",
    "    \"\"\"\n",
    "    Train the GAN\n",
    "    \"\"\"\n",
    "    input_real, input_z, _ = model_inputs(data_shape[1], data_shape[2], data_shape[3], z_dim)\n",
    "    d_loss, g_loss = model_loss(input_real, input_z, data_shape[3])\n",
    "    d_opt, g_opt = model_opt(d_loss, g_loss, learning_rate, beta1)\n",
    "    \n",
    "    steps = 0\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch_i in range(epoch_count):\n",
    "            for batch_images in get_batches(batch_size):\n",
    "                \n",
    "                # values range from -0.5 to 0.5, therefore scale to range -1, 1\n",
    "                batch_images = batch_images * 2\n",
    "                steps += 1\n",
    "            \n",
    "                batch_z = np.random.uniform(-1, 1, size=(batch_size, z_dim))\n",
    "                \n",
    "                _ = sess.run(d_opt, feed_dict={input_real: batch_images, input_z: batch_z})\n",
    "                _ = sess.run(g_opt, feed_dict={input_real: batch_images, input_z: batch_z})\n",
    "                \n",
    "                if steps % 400 == 0:\n",
    "                    # At the end of every 10 epochs, get the losses and print them out\n",
    "                    train_loss_d = d_loss.eval({input_z: batch_z, input_real: batch_images})\n",
    "                    train_loss_g = g_loss.eval({input_z: batch_z})\n",
    "\n",
    "                    print(\"Epoch {}/{}...\".format(epoch_i+1, epochs),\n",
    "                          \"Discriminator Loss: {:.4f}...\".format(train_loss_d),\n",
    "                          \"Generator Loss: {:.4f}\".format(train_loss_g))\n",
    "                    \n",
    "                    _ = show_generator_output(sess, 1, input_z, data_shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1... Discriminator Loss: 0.9585... Generator Loss: 0.9883\n",
      "Epoch 1/1... Discriminator Loss: 1.2632... Generator Loss: 0.7941\n",
      "Epoch 1/1... Discriminator Loss: 1.4067... Generator Loss: 0.8143\n",
      "Epoch 1/1... Discriminator Loss: 1.2508... Generator Loss: 0.7969\n",
      "Epoch 1/1... Discriminator Loss: 1.3632... Generator Loss: 0.7393\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-285f20263aaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-9dd4039855ce>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch_count, batch_size, z_dim, learning_rate, beta1, get_batches, data_shape)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minput_real\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_z\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_z\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minput_real\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_z\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_z\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m400\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "z_dim = 100\n",
    "learning_rate = 0.0002\n",
    "beta1 = 0.5\n",
    "epochs = 1\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    train(epochs, batch_size, z_dim, learning_rate, beta1, get_batches, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
